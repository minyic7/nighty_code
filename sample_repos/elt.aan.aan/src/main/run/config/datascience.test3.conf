# Data Science Test3 Configuration (Performance Testing)

environment = "test3"

spark {
  app.name = "ELT-AAN-DataScience-Test3"
  master = "yarn"
  
  sql {
    adaptive.enabled = true
    adaptive.coalescePartitions.enabled = true
    adaptive.skewJoin.enabled = true
    shuffle.partitions = 400
  }
  
  serializer = "org.apache.spark.serializer.KryoSerializer"
  
  executor {
    memory = "4g"
    cores = 3
    instances = 10
  }
  
  driver {
    memory = "2g"
    cores = 1
  }
}

database {
  url = "jdbc:postgresql://postgres-test3.internal:5432/datascience_perf"
  driver = "org.postgresql.Driver"
  user = ${?DB_USER}
  password = ${?DB_PASSWORD}
  
  connection_pool {
    initial_size = 8
    max_size = 30
    timeout = 30000
  }
}

paths {
  input = "s3a://data-lake-test3/raw/accounts/"
  output = "s3a://data-lake-test3/processed/aan/"
  checkpoint = "s3a://data-lake-test3/checkpoints/aan/"
  
  models = "s3a://ml-models-test3/aan/"
}

processing {
  batch_size = 25000
  parallelism = 12
  timeout_minutes = 180
  
  features {
    account_analysis = true
    risk_scoring = true
    notification_generation = true
  }
}

performance_testing {
  enabled = true
  target_throughput = "10MB/s"
  max_latency_ms = 5000
  load_pattern = "sustained"
}

monitoring {
  metrics_enabled = true
  profiling_enabled = true
  memory_monitoring = true
}

logging {
  level = "WARN"
  appenders = ["file", "metrics"]
  
  file {
    path = "/opt/logs/aan-test3.log"
    max_size = "200MB"
    max_files = 10
  }
}